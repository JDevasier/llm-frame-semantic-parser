{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "frame_descriptions = pd.read_csv('frame_descriptions_json.csv')\n",
    "\n",
    "system_prompt = \"\"\"### Task:\n",
    "You are given a sentence and a frame with its associated frame elements and sometimes examples. Your task is to label the frame elements in the sentence using JSON. Keys should only be one of the defined frame elements. Do not make up your own frame elements, and do not remove or change the input in any way. Identify the frame elements based on the highlighted target word. \n",
    "\n",
    "### Notes:\n",
    "- Return the tagged sentence in a ```json ``` code block.\n",
    "- Texts must not overlap.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"### Frame Information:\n",
    "{frame_info}\n",
    "\n",
    "### Input:\n",
    "{input_sentence}\n",
    "\"\"\"\n",
    "\n",
    "assistant_prompt = \"\"\"### Output: \n",
    "```json\n",
    "{output_sentence}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Name: Process_continue\n",
      "Frame Definition: An Event continues at a certain Place through Time. (Note that often when 'continue.v' occurs with definite time points, it denotes Resumption, which is out of frame here.)\n",
      "\n",
      "Frame Elements:\n",
      "Depictive (Extra-Thematic): Depictive phrase about the state of a focal participant.\n",
      "Manner (Peripheral): Manner in which the Event is continuing.\n",
      "Duration (Peripheral): This FE identifies the Duration of time over which the Event is ongoing.\n",
      "Event (Core-Unexpressed): Name of the Event which is continuing.\n",
      "Place (Peripheral): Where the Event takes place.\n",
      "Explanation (Extra-Thematic): The Explanation for which the Event occurs.\n",
      "Time (Peripheral): When the Event occurs.\n",
      "Next_subevent (Extra-Thematic): The Next_subevent of the overall Event.\n",
      "Circumstances (Extra-Thematic): Circumstances describe the state of the world (at a particular time and place) which is specifically independent of the event itself and any of its participants.\n",
      "Concessive (Extra-Thematic): This FE signifies that the state of affairs expressed by the main clause (containing the target) occurs or holds, and something other than that state of affairs would be expected given the state of affairs in the concessive clause.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(frame_descriptions.values[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in train_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "\n",
    "pd.DataFrame(test_samples).to_json('fn1.7-train-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_dev.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in val_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "pd.DataFrame(test_samples).head(200).to_json('fn1.7-val-prompts.jsonl', orient='records', lines=True)\n",
    "# pd.DataFrame(test_samples).to_json('fn1.7-val-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in test_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "\n",
    "pd.DataFrame(test_samples).to_json('fn1.7-test-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
