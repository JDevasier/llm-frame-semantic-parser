{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "frame_descriptions = pd.read_csv('frame_descriptions_json.csv')\n",
    "\n",
    "system_prompt = \"\"\"### Task:\n",
    "You are given a sentence and a frame with its associated frame elements and sometimes examples. Your task is to label the frame elements in the sentence using JSON. Keys should only be one of the defined frame elements. Do not make up your own frame elements, and do not remove or change the input in any way. Identify the frame elements based on the highlighted target word. \n",
    "\n",
    "### Notes:\n",
    "- Return the tagged sentence in a ```json ``` code block.\n",
    "- Texts must not overlap.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"### Frame Information:\n",
    "{frame_info}\n",
    "\n",
    "### Input:\n",
    "{input_sentence}\n",
    "\"\"\"\n",
    "\n",
    "assistant_prompt = \"\"\"### Output: \n",
    "```json\n",
    "{output_sentence}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Name: Abandonment\n",
      "Frame Definition: An Agent leaves behind a Theme effectively rendering it no longer within their control or of the normal security as one's property.\n",
      "\n",
      "Frame Elements:\n",
      "Agent (Core): The Agent is the person who acts to leave behind the Theme.\n",
      "Theme (Core): The Theme is the entity that is relinguished to no one from the Agent's possession.\n",
      "Place (Peripheral): The location where the Agent gives up the Theme.\n",
      "Time (Peripheral): When the Agent gives up the Theme.\n",
      "Manner (Peripheral): The style in which the Agent gives up the Theme.\n",
      "Duration (Peripheral): For what expanse of time the Agent has given up the Theme.\n",
      "Explanation (Extra-Thematic): Explanation denotes a proposition from which the act of abandonment logically follows.\n",
      "Depictive (Extra-Thematic): The FE Depictive describes the Agent during the abandoning event.\n",
      "Degree (Peripheral): The extent to which the Agent leaves the Theme behind.\n",
      "Means (Peripheral): An action performed by the Agent that accomplishes the action indicated by the target.\n",
      "Purpose (Peripheral): The purpose for which the Agent abandons the Theme.\n",
      "Event_description (Extra-Thematic): A description of the event as a whole.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(frame_descriptions.values[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "num_examples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_minimal_diverse_set(df, max_examples=5):\n",
    "    covered_fes = set()\n",
    "    \n",
    "    selected_samples = []\n",
    "    \n",
    "    samples_fes = [set([fe[0] for fe in fes]) for fes in df.fe.values if len(fes) > 0]\n",
    "    ignored_samples = set()\n",
    "    \n",
    "    while len(selected_samples) < max_examples and len(samples_fes) > 0:\n",
    "        most_diverse_sample = (None, -1)\n",
    "\n",
    "        for i, sample_fes in enumerate(samples_fes):\n",
    "            if i in ignored_samples:\n",
    "                continue\n",
    "            \n",
    "            sample_diversity = len(sample_fes - covered_fes)\n",
    "            \n",
    "            if sample_diversity > most_diverse_sample[1]:\n",
    "                most_diverse_sample = (i, len(sample_fes - covered_fes))\n",
    "            \n",
    "            if sample_diversity == 0:\n",
    "                ignored_samples.add(i)\n",
    "        \n",
    "        if most_diverse_sample[0] is None or most_diverse_sample[1] == 0:\n",
    "            break\n",
    "        \n",
    "        ignored_samples.add(most_diverse_sample[0])\n",
    "        selected_samples.append(most_diverse_sample[0])\n",
    "        covered_fes.update(samples_fes[most_diverse_sample[0]])\n",
    "    \n",
    "    return selected_samples\n",
    "            \n",
    "new_samples = []\n",
    "for frame, df in train_data.groupby(['frame']):\n",
    "    # print(frame)\n",
    "    # print([tuple([fe[0] for fe in fes]) for fes in df.fe.values if len(fes) > 0])\n",
    "    \n",
    "    diverse_index = greedy_minimal_diverse_set(df, max_examples=10)\n",
    "    diverse_samples = df.iloc[diverse_index]\n",
    "    extra_samples = df[~df.index.isin(diverse_index)].sample(n=max(num_examples-len(diverse_samples), 0), random_state=1) if len(diverse_samples) > num_examples else df[~df.index.isin(diverse_index)].head(n=max(num_examples-len(diverse_samples), 0))\n",
    "    new_samples.append(diverse_samples)\n",
    "    new_samples.append(extra_samples)\n",
    "\n",
    "new_samples = pd.concat(new_samples)\n",
    "new_train_data = new_samples.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "\n",
    "    sorted_fes = dict(sorted_fes)\n",
    "\n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in new_train_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "train_df = pd.DataFrame(test_samples)\n",
    "train_df.sample(frac=1).to_json('fn1.7-small-train-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_dev.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in val_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "val_df = pd.DataFrame(test_samples)\n",
    "val_df.to_json('fn1.7-val-prompts.jsonl', orient='records', lines=True)\n",
    "# pd.DataFrame(test_samples).to_json('fn1.7-val-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.854758)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tiktoken\n",
    "# import pandas as pd\n",
    "\n",
    "# # Count number of tokens in training data\n",
    "# encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "\n",
    "# a = train_df.messages.apply(lambda x: sum([len(encoding.encode(y['content'])) for y in x]))\n",
    "# b = val_df.messages.apply(lambda x: sum([len(encoding.encode(y['content'])) for y in x]))\n",
    "# a.sum() * (3/1000000) + b.sum() * (0.2 / 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in test_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "\n",
    "pd.DataFrame(test_samples).to_json('fn1.7-test-prompts.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
