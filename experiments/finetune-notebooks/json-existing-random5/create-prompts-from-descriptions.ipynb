{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "frame_descriptions = pd.read_csv('frame_descriptions_json.csv')\n",
    "\n",
    "system_prompt = \"\"\"### Task:\n",
    "You are given a sentence and a frame with its associated frame elements and sometimes examples. Your task is to label the frame elements in the sentence using JSON. Keys should only be one of the defined frame elements. Do not make up your own frame elements, and do not remove or change the input in any way. Identify the frame elements based on the highlighted target word. \n",
    "\n",
    "### Notes:\n",
    "- Return the tagged sentence in a ```json ``` code block.\n",
    "- Texts must not overlap.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"### Frame Information:\n",
    "{frame_info}\n",
    "\n",
    "### Input:\n",
    "{input_sentence}\n",
    "\"\"\"\n",
    "\n",
    "assistant_prompt = \"\"\"### Output: \n",
    "```json\n",
    "{output_sentence}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Name: Abandonment\n",
      "Frame Definition: An Agent leaves behind a Theme effectively rendering it no longer within their control or of the normal security as one's property.\n",
      "\n",
      "Frame Elements:\n",
      "Agent (Core): The Agent is the person who acts to leave behind the Theme.\n",
      "Theme (Core): The Theme is the entity that is relinguished to no one from the Agent's possession.\n",
      "Place (Peripheral): The location where the Agent gives up the Theme.\n",
      "Time (Peripheral): When the Agent gives up the Theme.\n",
      "Manner (Peripheral): The style in which the Agent gives up the Theme.\n",
      "Duration (Peripheral): For what expanse of time the Agent has given up the Theme.\n",
      "Explanation (Extra-Thematic): Explanation denotes a proposition from which the act of abandonment logically follows.\n",
      "Depictive (Extra-Thematic): The FE Depictive describes the Agent during the abandoning event.\n",
      "Degree (Peripheral): The extent to which the Agent leaves the Theme behind.\n",
      "Means (Peripheral): An action performed by the Agent that accomplishes the action indicated by the target.\n",
      "Purpose (Peripheral): The purpose for which the Agent abandons the Theme.\n",
      "Event_description (Extra-Thematic): A description of the event as a whole.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(frame_descriptions.values[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19909/3390577340.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  new_train_data = train_data.groupby(['frame']).apply(lambda x: x.sample(num_examples if len(x) > num_examples else len(x), random_state=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# Group by frame, lu. Get up to 5 random examples for each.\n",
    "num_examples = 5\n",
    "new_train_data = train_data.groupby(['frame']).apply(lambda x: x.sample(num_examples if len(x) > num_examples else len(x), random_state=1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in new_train_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "train_df = pd.DataFrame(test_samples)\n",
    "train_df.sample(frac=1).to_json('fn1.7-small-train-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1332309)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "# Count number of tokens in training data\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "\n",
    "a = train_df.messages.apply(lambda x: sum([len(encoding.encode(y['content'])) for y in x]))\n",
    "\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_dev.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in val_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "pd.DataFrame(test_samples).head(200).to_json('fn1.7-val-prompts.jsonl', orient='records', lines=True)\n",
    "# pd.DataFrame(test_samples).to_json('fn1.7-val-prompts.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/raw/os_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts for each sample:\n",
    "# - input_sentence w/ target span surrounded with ** for highlighting\n",
    "# - frame_name\n",
    "# - frame_elements (as text, not spans)\n",
    "\n",
    "def get_json_output(text, frame_elements):\n",
    "    sorted_fes = sorted(frame_elements.items(), key=lambda x: text.find(x[1]))\n",
    "    \n",
    "    sorted_fes = dict(sorted_fes)\n",
    "    \n",
    "    return sorted_fes\n",
    "\n",
    "test_samples = []\n",
    "frame_descriptions_dict = frame_descriptions.set_index('name').to_dict()['description']\n",
    "\n",
    "for row in test_data.iterrows():\n",
    "    # Index(['target', 'text', 'tokens', 'lu', 'frame', 'fe'], dtype='object')\n",
    "    idx, data = row\n",
    "    \n",
    "    # Get input sentence\n",
    "    input_sentence = data['text'][:data['target'][0]] + '**' + data['text'][data['target'][0]:data['target'][1]] + '**' + data['text'][data['target'][1]:]\n",
    "    \n",
    "    # Get frame name\n",
    "    frame_name = data['frame']\n",
    "    \n",
    "    # Get frame elements\n",
    "    frame_elements = {}\n",
    "    for fe in data['fe']:\n",
    "        frame_elements[fe[0]] = data['text'][fe[1]:fe[2]]\n",
    "        \n",
    "    # Get expected output\n",
    "    expected_output = get_json_output(data['text'], frame_elements)\n",
    "\n",
    "    sample = {\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': system_prompt\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt.format(frame_info=frame_descriptions_dict[frame_name].strip(), input_sentence=input_sentence)\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_prompt.format(output_sentence=expected_output)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if len(frame_elements) > 0:\n",
    "        test_samples.append(sample)\n",
    "\n",
    "\n",
    "pd.DataFrame(test_samples).to_json('fn1.7-test-prompts.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
